from typing import TypedDict, Annotated
from utils import get_llm, format_list_of_questions
from abc import abstractmethod
from langchain.output_parsers import PydanticOutputParser
from langchain_core.prompts import PromptTemplate
from pydantic import BaseModel, Field
from ENV import MODEL
import operator


class QAPair(BaseModel):
    question: str = Field(..., title="Question", description="The question")
    answer: str = Field(..., title="Answer", description="The answer")


class BaseLLM:
    def __init__(self, *args, **kwargs):
        self.llm = get_llm(
            temperature=kwargs.get('temperature', 0.0),
            max_tokens=kwargs.get('max_tokens', 2056),
        )
        self.prompt = self.create_prompt()

    @abstractmethod
    def create_prompt(self) -> str:
        pass


class Evaluator(BaseLLM):
    def __init__(self, temperature=0.5, *args, **kwargs):
        super().__init__(temperature=temperature, *args, **kwargs)
        
    def create_prompt(self, **kwargs) -> str:
        return kwargs.get(
            "prompt",
            """
            You are an expert in evaluating whether an answer generated by a large language model is semantically and/or logically correct or contains the correct answer given the true correct answer.
            Note that the answer generated might be lengthy or contain additional information that is not necessary. However, as long as it contains the correct answer, it should be considered correct.
            Just answer YES or NO. Don't answer anything else.
            """
        )

    async def aevaluate(self, answer: str, correct_answer: str) -> bool:
        response = await self.llm.ainvoke(
            [
                ("system", self.prompt),
                ("user", f"This is answer generated by a large language model: '{answer}'\n\nThis is the true correct answer '{correct_answer}'\n\nIs the answer generated correct?")
            ],
        )
        return "YES" in response.content.upper()
    
    def evaluate(self, answer: str, correct_answer: str) -> bool:
        response = self.llm.invoke(
            [
                ("system", self.prompt),
                ("user", f"This is answer generated by a large language model: '{answer}'\n\nThis is the true correct answer '{correct_answer}'\n\nIs the answer generated correct?")
            ],
        )
        return "YES" in response.content.upper()
    

class Generator(BaseLLM):
    def __init__(self, temperature=0.0, *args, **kwargs):
        super().__init__(temperature=temperature, *args, **kwargs)

    def create_prompt(self, **kwargs) -> str:
        return kwargs.get(
            "prompt",
            """
            You are the smartest expert in generating an answer given a question. Try your best to generate an answer that is as accurate as possible.
            Just answer the question. Don't output anything else.
            """
        )

    async def answer(self, question: str) -> str:
        response = await self.llm.ainvoke(
            [
                ("system", self.prompt),
                ("user", f"What is the answer to this question: '{question}'")
            ],
        )
        return response.content
    

class Discriminator(BaseLLM):
    def __init__(self, temperature=0.7, *args, **kwargs):
        super().__init__(temperature=temperature, *args, **kwargs)

    def create_prompt(self, **kwargs) -> str:
        return kwargs.get(
            "prompt",
            """
            You are an expert in rephrasing a question to be as challenging and tricky as possible that makes a large language model fail to generate the correct answer but is still clear to a human.
            Just rephrase the question. Don't output anything else.
            """
        )

    async def rephrase(self, question: str, true_answer: str, ai_answer: str) -> bool:
        response = await self.llm.ainvoke(
            [
                ("system", self.prompt),
                ("user", f"Here is the question: '{question}'\n\nHere is the true answer: '{true_answer}'\n\nHere is the answer generated by the large language model: '{ai_answer}'\n\nNow, rephrase the question in a way that makes a large language model fail to generate the correct answer but is clear to a human?")
            ],
        )
        return response.content
    

class QuestionGenerator(BaseLLM):
    def __init__(self, temperature=0.7, *args, **kwargs):
        super().__init__(temperature=temperature, *args, **kwargs)

    def create_prompt(self, **kwargs) -> str:
        return kwargs.get(
            "prompt",
            f"""
            You are an expert in generating a tricky question. It can be of any topic. Be as creative and tricky as possible.
            You must output both the question and the true answer to that question.
            """
        )
    #  that large language model {MODEL} is mostly unable to answer correctly but is clear to a human.

    async def generate(self, list_of_questions: list) -> QAPair:
        parser = PydanticOutputParser(pydantic_object=QAPair)

        prompt = PromptTemplate(
            template=self.prompt + "\n\n{format_instructions}\n\n{query}\n",
            input_variable=["query"],
            partial_variables={"format_instructions": parser.get_format_instructions()},
        )

        model = prompt | self.llm | parser

        response = await model.ainvoke({"query": f"Give me a question and the correct answer to that question.\n\nThe question must not be in this list:\n{format_list_of_questions(list_of_questions)}"})

        return response
    

class TrickyQuestionGenerator(TypedDict):
    start_num_question: int
    question: str
    answer: str
    ai_answer: str
    evaluator: Evaluator
    generator: Generator
    discriminator: Discriminator
    max_feedback_loop: int
    num_ai_answer: int
    qa_generator: QuestionGenerator
    list_of_questions: Annotated[list[str], operator.add]
